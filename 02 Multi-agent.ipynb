{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b457d60-5005-45f4-80c6-820904bb6a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 02 Multi-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2516821f-d92a-4bfa-ac33-3d317c0486f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "139c7865-2233-40b8-b10d-e40bdd293709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq mlflow langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b2a7fe-cab5-4546-ae90-6389c8606dd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id=\"\",\n",
    "    genie_agent_name=\"Billing Genie\",\n",
    "    client=WorkspaceClient(\n",
    "        host=\"\",\n",
    "        token=\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "LLM_ENDPOINT_NAME = \"gpt-4-1\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "tools = []\n",
    "uc_tool_names = [\n",
    "    \"main.billing.databricks_docs_vector_search\",\n",
    "    \"main.billing.get_dbu_discount\"\n",
    "]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "tools.extend(uc_toolkit.tools)\n",
    "\n",
    "prompt = \"\"\"\n",
    "- You are the Billing AI Assistant next to the Databricks Billing Dashboard. Users will ask you questions based on the information displayed on the dashboard.\n",
    "- **main.billing.databricks_docs_vector_search** can be used to search through Databricks' official documentation and can answer most general questions about Databricks.\n",
    "- **main.billing.get_dbu_discount** can get information about the available discounts for each purchase volume when reserving Azure Databricks DBU Reserved Instances (RI).\n",
    "\"\"\"\n",
    "docs_agent = create_react_agent(llm, tools=tools, prompt=prompt)\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "- You are the Billing AI Assistant next to the Databricks Billing Dashboard. Users will ask you questions based on the information displayed on the dashboard, and your task is to select the appropriate agent to answer the user's question.\n",
    "- Genie is an agent equipped with SQL capabilities. For inquiries requiring the use of cost data or real-time pricing queries, please select Genie to respond.\n",
    "- Docs can be used to search through Databricks' official documentation and information regarding Azure Databricks DBU Reserved Instances (RI), and can answer most general questions about Databricks.\n",
    "- If there are multiple questions, please ensure that each question is answered.\n",
    "- Sometimes, the assistant will respond with only a table. Based on the table's column names, if they are sufficient to answer the user's question, please select FINISH.\n",
    "- When the information provided is sufficient to address the user's inquiry, please select FINISH.\n",
    "- If no agent is needed or the question is irrelevant, please select FINISH.\n",
    "\"\"\"\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > 2:\n",
    "        return {\"next_node\": \"FINISH\"}\n",
    "    \n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[(\"Genie\", \"Docs\", \"FINISH\")]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node\n",
    "    }\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def final_answer(state):\n",
    "    prompt = \"\"\"\n",
    "    - You are the Billing AI Assistant next to the Databricks Billing Dashboard. Users will ask you questions based on the information displayed on the dashboard.\n",
    "    - Please respond to the user's most recent question in a professional and friendly manner, basing your answer solely on other assistant messages. Do not reply to irrelevant questions.\n",
    "    - No need to say 'based on the above information..'.\n",
    "    - The minimum purchase amount required to start receiving discounts at DBU is $12,500.\n",
    "    - For any DBU discount inquiries, please refer to the official website for additional information: https://azure.microsoft.com/en-us/pricing/details/databricks/.\n",
    "    - All monetary values provided by Genie are quoted in USD.\n",
    "    \"\"\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | llm\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "\n",
    "\n",
    "docs_node = functools.partial(agent_node, agent=docs_agent, name=\"Docs\")\n",
    "genie_node = functools.partial(agent_node, agent=genie_agent, name=\"Genie\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Genie\", genie_node)\n",
    "workflow.add_node(\"Docs\", docs_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "workflow.add_edge(\"Genie\", \"supervisor\")\n",
    "workflow.add_edge(\"Docs\", \"supervisor\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {\"Genie\": \"Genie\", \"Docs\": \"Docs\", \"FINISH\": \"final_answer\"}\n",
    ")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "multi_agent = workflow.compile()\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg})\n",
    "                    for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5593cef0-5155-4155-bace-efcd5ab05bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            # \"content\": \"Please provide the total expenditure for April 2025 and explain the purpose of the Databricks Job.\"\n",
    "            \"content\": \"Please help me forecast next year's total DBU expenditure and advise whether purchasing RI would be cost-effective.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "for event in AGENT.predict_stream(input_example):\n",
    "    print(event.delta.name, \"\\n\")\n",
    "    print(event.delta.content)\n",
    "    print(\"\\n-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56f22e38-0c6e-4626-a6d4-238fb5de43d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    "    DatabricksVectorSearchIndex\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=\"gpt-4-1\"),\n",
    "    DatabricksServingEndpoint(endpoint_name=\"text-embedding-3-large\"),\n",
    "    DatabricksGenieSpace(genie_space_id=\"\"),\n",
    "    DatabricksVectorSearchIndex(index_name=\"main.billing.databricks_documentation_index\"),\n",
    "    DatabricksFunction(function_name=\"main.billing.databricks_docs_vector_search\"),\n",
    "    DatabricksFunction(function_name=\"main.billing.get_dbu_discount\")\n",
    "]\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[f\"databricks-connect=={get_distribution('databricks-connect').version}\"],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3481f848-af3d-4968-b0d0-8ecef4874130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9a1844-07c7-4546-a472-d68ee5bbdab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "UC_MODEL_NAME = \"main.billing.billing_agent\"\n",
    "\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fffcd5af-1b6b-40b3-8952-91ddc8410ad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02 Multi-agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
